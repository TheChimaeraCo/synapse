import { convexClient } from "@/lib/convex";
import { api } from "@/convex/_generated/api";
import type { Id } from "@/convex/_generated/dataModel";

const EXTRACTION_PROMPT = `You are a fact extraction system. Analyze the conversation and extract structured facts about the user.

Return ONLY valid JSON array. Each fact:
{
  "category": "preference" | "fact" | "person" | "project" | "location" | "work" | "other",
  "key": "short_snake_case_key",
  "value": "the fact value",
  "confidence": 0.0-1.0
}

Rules:
- Only extract clear, stated facts (not inferences)
- Skip greetings, pleasantries, and AI responses
- Focus on user messages for facts about the user
- If no facts found, return []

Examples:
User: "I live in Austin and work at Google"
[{"category":"location","key":"city","value":"Austin","confidence":0.9},{"category":"work","key":"employer","value":"Google","confidence":0.9}]`;

interface ExtractedFact {
  category: string;
  key: string;
  value: string;
  confidence: number;
}

export async function extractKnowledge(
  messageId: Id<"messages">,
  agentId: Id<"agents">,
  gatewayId: Id<"gateways">,
  sessionId: Id<"sessions">,
) {
  try {
    // Get recent messages for context
    const [messages, sessionDoc] = await Promise.all([
      convexClient.query(api.functions.messages.getRecent, { sessionId, limit: 5 }),
      convexClient.query(api.functions.sessions.get, { id: sessionId }),
    ]);

    const userId = sessionDoc?.externalUserId;

    // Build conversation snippet
    const snippet = messages
      .map((m: any) => `${m.role}: ${m.content}`)
      .join("\n");

    if (!snippet.trim()) return;

    // Get AI config
    const [apiKey, providerSlug] = await Promise.all([
      convexClient.query(api.functions.config.get, { key: "ai_api_key" }),
      convexClient.query(api.functions.config.get, { key: "ai_provider" }),
    ]);

    const provider = providerSlug || "anthropic";
    const key = apiKey || process.env.ANTHROPIC_API_KEY || "";
    if (!key) return;

    const envMap: Record<string, string> = {
      anthropic: "ANTHROPIC_API_KEY",
      openai: "OPENAI_API_KEY",
      google: "GEMINI_API_KEY",
    };
    if (envMap[provider]) process.env[envMap[provider]] = key;

    const { registerBuiltInApiProviders, getModel, streamSimple } = await import("@mariozechner/pi-ai");
    registerBuiltInApiProviders();

    // Use cheapest model available
    const extractModel = provider === "anthropic" ? "claude-haiku-3-20250514" : "claude-haiku-3-20250514";
    const model = getModel(provider as any, extractModel as any);
    if (!model) return;

    const context: any = {
      systemPrompt: EXTRACTION_PROMPT,
      messages: [
        { role: "user" as const, content: snippet, timestamp: Date.now() },
      ],
    };

    let fullContent = "";
    const stream = streamSimple(model, context, { maxTokens: 1024, apiKey: key });
    for await (const event of stream) {
      if (event.type === "text_delta") {
        fullContent += event.delta;
      }
    }

    // Parse facts
    let facts: ExtractedFact[] = [];
    try {
      // Extract JSON from response (handle markdown code blocks)
      const jsonMatch = fullContent.match(/\[[\s\S]*\]/);
      if (jsonMatch) {
        facts = JSON.parse(jsonMatch[0]);
      }
    } catch {
      console.error("Knowledge extraction parse error:", fullContent.slice(0, 200));
      return;
    }

    // Store facts and trigger embedding generation
    for (const fact of facts) {
      if (!fact.key || !fact.value || fact.confidence < 0.5) continue;
      try {
        const knowledgeId = await convexClient.mutation(api.functions.knowledge.upsert, {
          agentId,
          gatewayId,
          userId,
          category: fact.category || "other",
          key: fact.key,
          value: fact.value,
          confidence: fact.confidence,
          source: "conversation",
          sourceMessageId: messageId,
        });

        // Trigger async embedding generation for the new/updated entry
        if (knowledgeId) {
          try {
            // Fire and forget - embedding will be generated by the cron if this fails
            const { generateEmbeddingOpenAI } = await import("@/lib/embeddings");
            const openaiKey = await convexClient.query(api.functions.config.get, { key: "openai_api_key" });
            if (openaiKey) {
              const text = `${fact.key} ${fact.value}`;
              const embedding = await generateEmbeddingOpenAI(text, openaiKey);
              if (embedding) {
                await convexClient.mutation(api.functions.knowledge.update, {
                  id: knowledgeId as any,
                  // We can't set embedding through the public update mutation,
                  // it will be picked up by the hourly cron job
                });
              }
            }
          } catch {
            // Embedding will be generated by the hourly cron job
          }
        }
      } catch (err) {
        console.error("Knowledge upsert error:", err);
      }
    }
  } catch (err) {
    console.error("Knowledge extraction failed:", err);
  }
}
